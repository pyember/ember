[tool.poetry]
name = "ember-ai"
version = "0.1.0"
description = "Compositional framework for building and orchestrating Compound AI Systems and Networks of Networks (NONs)."
authors = ["Jared Quincy Davis <jaredq@cs.stanford.edu>"]
maintainers = ["Ember Team <team@pyember.org>"]
readme = "README.md"
license = "Apache-2.0"
repository = "https://github.com/pyember/ember"
documentation = "https://docs.pyember.org"
homepage = "https://pyember.org"
keywords = ["AI", "LLM", "Networks of Networks", "Machine Learning", "Compound AI", "Orchestration", "AI Framework", "LLM Orchestration", "AI System Design"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "Intended Audience :: Information Technology",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Software Development :: Libraries :: Application Frameworks",
    "Operating System :: OS Independent",
]
packages = [
    { include = "ember", from = "src" },
]

[tool.poetry.dependencies]
python = ">=3.11,<3.13"  # Add Python 3.12 support
pandas = ">=1.0.0,<2.2.0"
numpy = ">=1.21.0,<1.27.0"

# Core dependencies
pydantic = "^2.7.4"
pydantic-core = "^2.18.4"
pydantic-settings = "^2.3.0"
PyYAML = "^6.0.1"
typing_extensions = "^4.12.2"

# LLM providers - Using optional dependencies for flexibility
openai = {version = "^1.57.2", optional = true}
anthropic = {version = "^0.40.0", optional = true}
google-generativeai = {version = "^0.8.3", optional = true}
ibm-watsonx-ai = {version = "^1.1.25", optional = true}

# HTTP and async - Critical core functionality
aiohttp = "^3.9.5"
aiosignal = "^1.3.1"
httpx = "^0.27.0"
requests = "^2.32.2"

# Data processing - Optional for advanced users
datasets = {version = "^2.20.0", optional = false}
scikit-learn = {version = "^1.6.0", optional = true}
scipy = {version = "^1.13.1", optional = true}
huggingface-hub = {version = "^0.26.5", optional = true}
pyarrow = {version = "^16.1.0", optional = true}
"pyarrow-hotfix" = {version = "^0.6", optional = true}

# Visualization - Optional for users who need it
matplotlib = {version = "^3.9.1", optional = true}
prettytable = {version = "^3.12.0", optional = true}

# Core utilities - Required for robust operation
tqdm = "^4.67.1"
tenacity = "^9.0.0"
cachetools = "^5.4.0"
dill = "^0.3.8"

# Google API dependencies - Only needed for Google provider
google-ai-generativelanguage = {version = "^0.6.6", optional = true}
google-api-core = {version = "^2.19.1", optional = true}
google-api-python-client = {version = "^2.139.0", optional = true}
google-auth = {version = "^2.32.0", optional = true}
google-auth-httplib2 = {version = "^0.2.0", optional = true}
googleapis-common-protos = {version = "^1.63.2", optional = true}

# Basic required dependencies
annotated-types = "^0.7.0"
anyio = "^4.4.0"
attrs = "^23.2.0"
certifi = "^2024.6.2"
charset-normalizer = "^3.3.2"

# For dependency resolution, these will be managed by poetry automatically
packaging = "^24.1"
six = "^1.16.0"
idna = "^3.7"
urllib3 = "^1.26.19"
sniffio = "^1.3.1"

[tool.poetry.extras]
# Main extras groups
all = ["openai", "anthropic", "google", "ibm", "data", "viz", "dev", "docs"]
minimal = ["openai"]  # Minimal viable installation with just OpenAI

# Provider-specific extras
openai = ["openai"]
anthropic = ["anthropic"]
google = ["google-generativeai", "google-ai-generativelanguage", "google-api-core", "google-api-python-client", "google-auth", "google-auth-httplib2", "googleapis-common-protos"]
ibm = ["ibm-watsonx-ai"]
allproviders = ["openai", "anthropic", "google", "ibm"]

# Feature-specific extras
data = ["datasets", "scikit-learn", "scipy", "huggingface-hub", "pyarrow", "pyarrow-hotfix"]
viz = ["matplotlib", "prettytable"]

# Developer extras
dev = ["pytest", "parameterized", "jupyterlab", "ipykernel", "pytest-cov", "hypothesis", "mutmut", "tox", "black", "isort", "mypy", "pylint", "pre-commit", "ruff"]
docs = ["sphinx", "sphinx-rtd-theme", "nbsphinx", "myst-parser", "jupyter", "notebook"]

[tool.poetry.group.dev.dependencies]
# Testing
pytest = "8.3.2"
parameterized = "0.9.0"
pytest-cov = "4.1.0"
hypothesis = "6.99.0"
mutmut = "2.4.4"
tox = "4.11.4"

# Development environment
jupyterlab = "4.0.6"
ipykernel = "6.26.0"
black = "^23.12.0"
isort = "^5.12.0"
mypy = "^1.7.1"
pylint = "^3.0.2"
pre-commit = "^3.5.0"
ruff = "^0.1.6"

[tool.poetry.group.docs]
optional = true

[tool.poetry.group.docs.dependencies]
sphinx = "^7.1.0"
sphinx-rtd-theme = "^1.3.0"
nbsphinx = "^0.9.3"
myst-parser = "^2.0.0"

[tool.pytest.ini_options]
pythonpath = [
    "src",
    "tests"
]
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
addopts = "--import-mode=importlib --cov=src/ember --cov-report=term --cov-report=html --cov-report=xml"

[tool.coverage.run]
source = ["src/ember"]
omit = ["*/__init__.py", "*/test_*.py", "tests/*"]
branch = true

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise NotImplementedError",
    "if TYPE_CHECKING",
    "pass",
    "\\.\\.\\."
]
fail_under = 90
show_missing = true

[tool.hypothesis]
deadline = 500
max_examples = 100
verbosity = 1
suppress_health_check = ["too_slow"]

[tool.black]
line-length = 88
target-version = ["py311"]
include = '\.pyi?$'

[tool.isort]
profile = "black"
line_length = 88
multi_line_output = 3

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
strict_optional = true

[tool.ruff]
line-length = 88
target-version = "py311"
select = ["E", "F", "B", "I"]
ignore = []

[build-system]
requires = ["poetry-core>=1.5.0"]
build-backend = "poetry.core.masonry.api"

[tool.poetry.plugins."ember.dataset_preppers"]
truthful_qa = "ember.core.utils.data.datasets_registry.truthful_qa:TruthfulQAPrepper"
short_answer = "ember.core.utils.data.datasets_registry.short_answer:ShortAnswerPrepper"
commonsense_qa = "ember.core.utils.data.datasets_registry.commonsense_qa:CommonsenseQAPrepper"
halueval = "ember.core.utils.data.datasets_registry.halueval:HaluEvalPrepper"
mmlu = "ember.core.utils.data.datasets_registry.mmlu:MMLUPrepper"

[tool.setuptools]
package-dir = {"" = "src"}
packages = ["ember"]

[tool.poetry.scripts]
ember = "ember.cli:main"